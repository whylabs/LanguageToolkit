{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDUtcLEmtIlk"
      },
      "outputs": [],
      "source": [
        "%pip install langkit[all]==0.0.24.dev2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we want the standard LLM metrics for English prompts, but we don't want any metrics on the responses since they're in a different unsupported language. We can use the default configurations for the prompt metrics and set the response metric configurations to `None` to turn them off.\n"
      ],
      "metadata": {
        "id": "mqPATL2OvFAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langkit.llm_metrics as llmm\n",
        "from langkit import LangKitConfig\n",
        "\n",
        "no_response_config = LangKitConfig(\n",
        "    prompt_languages={\"en\"},\n",
        "    response_languages={\"pt\"},\n",
        "    response_pattern_file_path=None,  # regexes are semi-international, could leave this as default\n",
        "    sentiment_lexicon=None,  # use multilingual sentiment model for the prompt\n",
        "    response_sentiment_lexicon=None,\n",
        "    response_sentiment_model_path=None,\n",
        "    response_theme_file_path=None,\n",
        "    response_topic_model_path=None,\n",
        "    response_toxicity_model_path=None,\n",
        "    response_transformer_name=None,\n",
        ")\n",
        "schema = llmm.init(config=no_response_config)"
      ],
      "metadata": {
        "id": "0U_TM-3Xtx-Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whylogs as why\n",
        "from langkit.whylogs.samples import load_chats, show_first_chat\n",
        "\n",
        "chats = load_chats()\n",
        "results = why.log(chats, schema=schema)\n",
        "\n",
        "for column in results.view().get_columns().keys():\n",
        "  print(column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQDvPLvR8E_U",
        "outputId": "c4450822-3795-40a7-fb03-36109d35d745"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ No session found. Call whylogs.init() to initialize a session and authenticate. See https://docs.whylabs.ai/docs/whylabs-whylogs-init for more information.\n",
            "prompt\n",
            "response\n",
            "prompt.has_patterns\n",
            "prompt.sentiment_multi\n",
            "prompt.flesch_reading_ease\n",
            "prompt.automated_readability_index\n",
            "prompt.aggregate_reading_level\n",
            "prompt.syllable_count\n",
            "prompt.lexicon_count\n",
            "prompt.sentence_count\n",
            "prompt.character_count\n",
            "prompt.letter_count\n",
            "prompt.polysyllable_count\n",
            "prompt.monosyllable_count\n",
            "prompt.difficult_words\n",
            "prompt.jailbreak_similarity\n",
            "prompt.toxicity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a multilingual sentiment model that includes Portuguese, so we can enable it to track response sentiment."
      ],
      "metadata": {
        "id": "bH4ZWQBLe0hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt_sentiment_config = LangKitConfig(\n",
        "    prompt_languages={\"en\"},\n",
        "    response_languages={\"pt\"},\n",
        "    response_pattern_file_path=None,\n",
        "    sentiment_lexicon=None,  # disable English-only sentiment model\n",
        "    response_sentiment_lexicon=None,\n",
        "    #response_sentiment_model_path=None,  # enable (don't disable) multilingual sentiment model\n",
        "    response_theme_file_path=None,\n",
        "    response_topic_model_path=None,\n",
        "    response_toxicity_model_path=None,\n",
        "    response_transformer_name=None,\n",
        ")\n",
        "schema = llmm.init(config=pt_sentiment_config)\n",
        "results = why.log(chats, schema=schema)\n",
        "\n",
        "for column in results.view().get_columns().keys():\n",
        "  print(column)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxRf98Ujfr6D",
        "outputId": "73e9efc0-65d6-41e8-b225-e4296a228966"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt\n",
            "response\n",
            "prompt.has_patterns\n",
            "prompt.sentiment_multi\n",
            "response.sentiment_multi\n",
            "prompt.flesch_reading_ease\n",
            "prompt.automated_readability_index\n",
            "prompt.aggregate_reading_level\n",
            "prompt.syllable_count\n",
            "prompt.lexicon_count\n",
            "prompt.sentence_count\n",
            "prompt.character_count\n",
            "prompt.letter_count\n",
            "prompt.polysyllable_count\n",
            "prompt.monosyllable_count\n",
            "prompt.difficult_words\n",
            "prompt.jailbreak_similarity\n",
            "prompt.toxicity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The toxicity module supports translation, so we can configure a Portuguese to English translator and track response toxicity with the English-only model."
      ],
      "metadata": {
        "id": "jnpjxIGKg9ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from transformers import AutoProcessor, SeamlessM4TModel\n",
        "from langkit.translator import Translator\n",
        "\n",
        "class Seamless_M4T(Translator):\n",
        "  def __init__(self, src_lang=\"eng\", tgt_lang=\"eng\"):\n",
        "    self._processor = AutoProcessor.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n",
        "    self._model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n",
        "    self._src_lang = src_lang\n",
        "    self._tgt_lang = tgt_lang\n",
        "\n",
        "  def translate(self, text):\n",
        "    text_inputs = self._processor(text = text, src_lang=self._src_lang, tgt_lang=self._tgt_lang, return_tensors=\"pt\")\n",
        "    output_tokens = self._model.generate(**text_inputs, tgt_lang=self._tgt_lang, generate_speech=False)\n",
        "    return self._processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
        "\n",
        "print(Seamless_M4T(\"por\", \"eng\").translate(\"Olá, o meu cão é lindo.\"))\n",
        "\"\"\"\n",
        "\n",
        "from langkit.translator import Translator\n",
        "class FakeTranslator(Translator):\n",
        "    def translate(self, text):\n",
        "        return \"Hello, my dog is beautiful\""
      ],
      "metadata": {
        "id": "b5quNo4sg-Mb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langkit.toxicity as tx\n",
        "tx.RESPONSE_TRANSLATOR = FakeTranslator()  # Seamless_M4T(\"por\", \"eng\")\n",
        "\n",
        "translated_config = LangKitConfig(\n",
        "    prompt_languages={\"en\"},\n",
        "    response_languages={\"pt\"},\n",
        "    response_pattern_file_path=None,\n",
        "    sentiment_lexicon=None,\n",
        "    response_sentiment_lexicon=None,\n",
        "    response_sentiment_model_path=None,\n",
        "    response_theme_file_path=None,\n",
        "    response_topic_model_path=None,\n",
        "    # response_toxicity_model_path=None,\n",
        "    response_transformer_name=None,\n",
        ")\n",
        "schema = llmm.init(config=translated_config)\n",
        "results = why.log({\"prompt\": \"Hi, how's your dog?\", \"response\": \"Olá, o meu cão é lindo.\"}, schema=schema)\n",
        "\n",
        "for column in results.view().get_columns().keys():\n",
        "  print(column)"
      ],
      "metadata": {
        "id": "YNo4hIxzhxBq",
        "outputId": "e4a2669e-1e55-4a7b-9aef-931391fc2656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt\n",
            "response\n",
            "prompt.has_patterns\n",
            "prompt.sentiment_multi\n",
            "prompt.flesch_reading_ease\n",
            "prompt.automated_readability_index\n",
            "prompt.aggregate_reading_level\n",
            "prompt.syllable_count\n",
            "prompt.lexicon_count\n",
            "prompt.sentence_count\n",
            "prompt.character_count\n",
            "prompt.letter_count\n",
            "prompt.polysyllable_count\n",
            "prompt.monosyllable_count\n",
            "prompt.difficult_words\n",
            "prompt.jailbreak_similarity\n",
            "prompt.toxicity\n",
            "response.toxicity\n"
          ]
        }
      ]
    }
  ]
}
